{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Natural Disasters in the US"
      ],
      "metadata": {
        "id": "Wdgx0cjz5pkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "7aT5rLuM5wIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data compilation looks at the change in climate-related natural disaster in the United States over the past 40 years, starting in 1980. The compilation uses a data set taken from the IMF Climate Change Dashboard which records the frequency of natural disasters over time of dozens of countries. These natural disasters include storms, floods, droughts, landslides, wildfires, and extreme temperatures.\n",
        "\n",
        "The process below describes how to download the dataset, create a dataframe, and then narrow down the specific information you want to examine and save it as its own subset."
      ],
      "metadata": {
        "id": "xpWgus2_54MQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process"
      ],
      "metadata": {
        "id": "1U-PWfs77ala"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Started"
      ],
      "metadata": {
        "id": "yXNN5zGl7dns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the .csv file from the IMF Climate Change Dashboard\n",
        "  https://climatedata.imf.org/pages/climatechange-data\n",
        "\n",
        "2. Mount your Google Drive"
      ],
      "metadata": {
        "id": "OUENzfyNALF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0wxVy2FAusN",
        "outputId": "aba64deb-62fb-4052-d295-5442c38a8349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Import the required packages  "
      ],
      "metadata": {
        "id": "TbpGPoeABEuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Sw9Lfpud5u9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating your dataframe"
      ],
      "metadata": {
        "id": "mezf-CzfCNMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn the .csv file into a usable dataframe. We can do this by setting whatever we want to name our data frame equal to `pd.read_csv()`, with the file's location inside of the parentheses. I named my dataframe \"df\".\n",
        "\n",
        "This should look something like this:\n"
      ],
      "metadata": {
        "id": "3U772NQlEnVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('gdrive/MyDrive/ENGL 105/Climate-related_Disasters_Frequency.csv')"
      ],
      "metadata": {
        "id": "lEKq21v2JZZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating your Subset"
      ],
      "metadata": {
        "id": "sRw-NBZhLl-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data frame contains hundreds of rows with information about dozens of countries, so now you are going to isolate the data for just the country you want to look at. For this compilation, I looked at just the United States."
      ],
      "metadata": {
        "id": "AOcFPIaWLreb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do this, I used the `.iloc` function. The name of your dataframe with `.iloc` will look up a set of specified rows and columns. You list the number row or rows you want first, then a comma, then the column or columns. To find a range of either, use a colon between the top and bottom of the range."
      ],
      "metadata": {
        "id": "WDQnMure7fb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this data compilation, I am just looking at total disasters per year for the US, which are located in row 924. Years 1980-2020 were located in columns 10-51."
      ],
      "metadata": {
        "id": "eTreWj0z9fLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[924,10:51]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHXjLhu1AWOe",
        "outputId": "06a162c3-bf1d-4911-923a-064935a4efe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F1980     7.0\n",
              "F1981     4.0\n",
              "F1982    13.0\n",
              "F1983     9.0\n",
              "F1984    14.0\n",
              "F1985    15.0\n",
              "F1986     6.0\n",
              "F1987     9.0\n",
              "F1988    22.0\n",
              "F1989    17.0\n",
              "F1990    21.0\n",
              "F1991    35.0\n",
              "F1992    29.0\n",
              "F1993    28.0\n",
              "F1994    14.0\n",
              "F1995    17.0\n",
              "F1996    14.0\n",
              "F1997    33.0\n",
              "F1998    32.0\n",
              "F1999    22.0\n",
              "F2000    30.0\n",
              "F2001    26.0\n",
              "F2002    29.0\n",
              "F2003    22.0\n",
              "F2004    20.0\n",
              "F2005    16.0\n",
              "F2006    28.0\n",
              "F2007    23.0\n",
              "F2008    21.0\n",
              "F2009    17.0\n",
              "F2010    15.0\n",
              "F2011    23.0\n",
              "F2012    25.0\n",
              "F2013    28.0\n",
              "F2014    19.0\n",
              "F2015    29.0\n",
              "F2016    26.0\n",
              "F2017    24.0\n",
              "F2018    19.0\n",
              "F2019    20.0\n",
              "F2020    23.0\n",
              "Name: 924, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I gave this data set a name. I called the new data set USTotalDisasters."
      ],
      "metadata": {
        "id": "u9Olhd1wxrGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USTotalDisasters = df.iloc[924,10:51]"
      ],
      "metadata": {
        "id": "-qlBBPv1x32q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to save this subset as its own .csv file. To do this I use the `.tocsv` function."
      ],
      "metadata": {
        "id": "yjmDNBoHwszS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USTotalDisasters.to_csv(\"USTotalDisasters.csv\", index=False)"
      ],
      "metadata": {
        "id": "wJgSKdnvxA5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}